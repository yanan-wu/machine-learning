#### 经验误差与过拟合
##### 错误率
通常我们把分类错误的样本数占样本总数的比例称为错误率 (error
rate) ，即如果在 m 个样本中有 α 个样本分类错误，则错误率 E= α/m。

##### 精度
精度 = 1 - 错误率

##### 经验误差
学习器在训练集上的误差称为训练误差(training error)或经验误差(empirical error)。

##### 泛化误差
在新样本上的误差称为泛化误差(generalization error)。

##### 过拟合
学习器把训练样本学得"太好"了的时候，很可能巳经把训练样本自身的一些特点当作了所有潜在样本都会具有的一般性质，这样就会导致泛化性能下降这种现象在机器学习中称为过拟合(overfitting)。

##### 欠拟合
是指对训练样本的一般性质尚未学好。

#### 评估方法

##### 留出法
留出法 (hold-out)直接将数据集 D 划分为两个互斥的集合，其中一个
集合作为训练集 S，另一个作为测试集 T， 即 D = B∪T ， S∩T= ∅.在 S 上训
练出模型后，用 T 来评估其测试误差，作为对泛化误差的估计。常见做法是将大约 2/3 - 4/5 的
样本用于训练，剩余样本用于测试。

##### 交叉验证法
交叉验证法 (cross validation) 先将数据集 D 划分为 k 个大小相似的
互斥子集， 即 D = D1∪D2∪... ∪Dk, Di∩Dj = ø (i ≠ j )。每个子集 Di 都
尽可能保持数据分布的一致性，即从 D 中 通过分层采样得到。然后，每次用
k-1 个子集的并集作为训练集；余下的那个子集作为测试集;这样就可获得 k
组训练/测试集，从而可进行 k 次训练和测试，最终返回的是这 k 个测试结果的均值。

##### 自助法
自助法(bootstrapping)是一个比较好的解决方案，它直接以自助采样
法 (bootstrap sampling)为基础。给定包含 m 个样本的数据集 D，我们对它进行采样产生数据集 D': 每次随机从 D 中挑选一个
样本，将其拷贝放入 D'，然后再将该样本放回初始数据集 D 中，使得该样本在
下次采样时仍有可能被采到;这个过程重复执行 m 次后，我们就得到了包含 m
个样本的数据集 D'。我们可将 D' 用作训练集，D\D' 用作测试集。

#### 性能度量

##### 均方误差
是回归任务最常用的性能度量。

##### 错误率和精度
是分类任务中最常用的两种性能度量，既适用于二分类任务，也适用于多分类任务.错误率是分类错误的样本数占样
本总数的比例，精度则是分类正确的样本数占样本总数的比例。


##### 查准率、查全率与 F1
对于二分类问题，可将样例根据其真实类别与学习器预测类别的组合划分为真正例 (true positive)、假正例 (false positive)、真反倒 (true negative) 、
假反例 (false negative) 四种情形，令 TP、 FP、 TN、 FN 分别表示其对应的
样例数，则显然有 TP+FP+TN+FN=样例总数。
查准率 P 与查全率 R 分别定义为

